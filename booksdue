#!/usr/bin/env python
#
# Download a list of books due from the Minuteman Library Network
# in Massachusetts.
#
# Win Treese
# treese@acm.org
#
# Last modified on Fri Apr  3 21:45:11 EDT 2009 by treese

import mechanize
from bs4 import BeautifulSoup

from HTMLParser import HTMLParser
from optparse import OptionParser
import datetime
import os
import sys
import re
import string
import logging

# Main configuration
urlbase = "https://library.minlib.net"

class MyTableParser(HTMLParser):
    def __init__(self):
        self.intable = False
        self.incell = False
        self.inrow = False
        self.inspan = False
        self.label = False
        self.celldata = ''
        self.rowdata = []
        self.tabledata = []
        HTMLParser.__init__(self)
    def handle_starttag(self, tag, attrs):
        if tag == 'table':
            self.intable = True
        elif tag == 'tr':
            self.inrow = True
        elif tag == 'td':
            self.incell = True
        elif tag == 'span':
            self.inspan = True
        elif tag == 'label':
            self.label = True
    def handle_data(self, data):
        if self.incell:
            self.celldata = self.celldata + ' ' + data.strip()
    def handle_endtag(self, tag):
        if tag == 'table':
            self.intable = False
        elif tag == 'tr':
            self.inrow = False
            self.tabledata.append(self.rowdata)
            self.rowdata = []
        elif tag == 'td':
            self.incell = False
            self.rowdata.append(self.celldata)
            self.celldata = ''
        elif tag == 'span':
            self.inspan = False
        elif tag == 'label':
            self.label = False

class MlnFetcher(object):
    def __init__(self, account, pin):
        super(MlnFetcher, self).__init__()
        self.account = account
        self.pin = pin
    def fetch(self):
        br = mechanize.Browser()
        br.set_handle_robots(False)     # Don't worry about robots.txt for this.
        myurl = urlbase + "/patroninfo/"
        try:
            response = br.open(myurl)
        except mechanize.URLError, (errno, errmsg):
            sys.stderr.write('Cannot open URL %s: %s' % (myurl, errmsg))
            sys.exit(-1)

        assert br.viewing_html()
        br.select_form(nr = 0)
        br["code"] = self.account
        br["pin"] = self.pin

        response = br.submit()
        data = response.read()
        logging.debug(data)

        soup = BeautifulSoup(data, "html5lib")



        # If there are no books checked out, and there are fines,
        # then punt.

        nocheckouts = False
        if data.find('0 Items currently checked out') >= 0 \
            or data.find('patFuncTitle">Reading History') >= 0 \
            or data.find('buttonText">Pay') >= 0 \
            or data.find('ITEMS CHECKED OUT') == -1:
            nocheckouts = True

        if (data.find('the information you submitted was invalid') >= 0 ):
            return [(None, 'Bad account number or password')]

        # Look for books on hold.

        match = re.search(r'\<a [^>]*>(.*request[^<]+\.)</a>', data)
        if match != None:
            if match.group(1) != "0 requests (holds).":
                print match.group(1)

        # The HTML on this page isn't very good, so we pull out
        # the important table with a regexp, and then parse the HTML.

        match = re.search('\<table[^>]*patFunc".*</table>', data, re.DOTALL)

        booklist = []
        if match != None:
            parser = MyTableParser()
            input = match.group(0).replace("& ", "and ")
            parser.feed(input)

            if nocheckouts:
                return [(None, 'Nothing checked out')]
            for book in parser.tabledata[1:]:
                title = book[1].split('/')[0].strip()
                logging.debug("Book info: %s" % str(book))
                xdate = book[4].split()[1].split('-')
                year = xdate[2][0:2]
                logging.debug("xdate %s year %s" % (xdate, year))
                duedate = datetime.datetime(2000 + int(year), int(xdate[0]),
                                            int(xdate[1]))
                logging.debug("Book parsed: %s %s" % (duedate, title))
                booklist.append((duedate, title))
        return booklist

# Config file is one account per line, no comments.
# name account# pin

def read_config(filename, args):
    accounts = []
    args = [x.lower() for x in args]
    f = open(filename)
    for x in f.readlines():
        acct = x.split()
        if len(args) == 0 or acct[0].lower() in args:
            accounts.append(acct)
    return accounts

def compareNames(book1, book2):
    (duedate1, title1) = book1
    (duedate2, title2) = book2
    return cmp(title1, title2)

def compareDates(book1, book2):
    (duedate1, title1) = book1
    (duedate2, title2) = book2
    if duedate1 < duedate2:
        return -1
    if duedate1 == duedate2:
        return 0
    return 1

def main():
    usage = "%prog [options] [accounts]"
    defaultconfig = ".mln.conf"
    config = os.getenv("HOME") + "/" + defaultconfig
    cmdparser = OptionParser(usage)
    cmdparser.add_option("-c", "--config", type="string", dest="config",
                        help="Configuration file to use; default is ~/" +
                        defaultconfig, default=config)
    cmdparser.add_option("-d", "--by-date", action="store_true", dest="bydate",
                         help="Sort list by due date", default=True)
    cmdparser.add_option("-n", "--by-name", action="store_false", dest="bydate",
                         help="Sort list by name")
    cmdparser.add_option("-w", "--warn", type="int", dest="warndays",
                        help="Print warning for books due in N days", default=100)
    cmdparser.add_option("-z", "--debug", action="store_true", dest="debug",
                         help="Enable debugging", default=False)

    (options, args) = cmdparser.parse_args()
    if options.debug:
        logging.basicConfig(level=logging.DEBUG)

    # Print the base URL as a handy link to click on in an email.
    print "\n%s\n\n" % (urlbase)

    accounts = read_config(options.config, args)
    for acct in accounts:
        fetcher = MlnFetcher(acct[1], acct[2])
        # Print by  name
        print acct[0]
        print "----------"
        booklist = fetcher.fetch()
        logging.debug(booklist)
        if len(booklist) > 1:
            if options.bydate:
                booklist.sort(compareDates)
            else:
                booklist.sort(compareNames)
        for book in booklist:
            (duedate,title) = book
            if duedate == None:
                print title
            else:
                now = datetime.datetime.today()
                if duedate - now < datetime.timedelta(options.warndays):
                    print duedate.strftime('%m/%d/%Y'), title
        print ""

if __name__ == "__main__":
    main()
